"""
–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥—É–ª—è feature engineering.

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç, –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å build_features –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è
–≤—Å–µ—Ö —Ñ–∏—á–µ–π –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
"""

import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.data.load_data import load_train, load_test
from src.data.save_data import save_dataframe, load_dataframe
from src.features.build_features import (
    build_all_features, 
    build_features_for_test,
    get_feature_list
)


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏."""
    
    print("=" * 80)
    print("üöÄ –ü–†–ò–ú–ï–† –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø FEATURE ENGINEERING")
    print("=" * 80)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    train = load_train()
    test = load_test()
    
    print(f"   Train: {train.shape}")
    print(f"   Test: {test.shape}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏—á–µ–π –¥–ª—è train (—Å sales)
    print("\nüîß –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏—á–µ–π –¥–ª—è train...")
    train_features = build_all_features(
        train,
        feature_groups=None,  # –í—Å–µ –≥—Ä—É–ø–ø—ã
        lag_periods=[1, 7, 14, 30, 90, 365],
        rolling_windows=[7, 30],
        verbose=True
    )
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ñ–∏—á–µ–π
    feature_cols = get_feature_list(train_features)
    print(f"\nüìä –°–æ–∑–¥–∞–Ω–æ {len(feature_cols)} —Ñ–∏—á–µ–π:")
    print(f"   –ü—Ä–∏–º–µ—Ä—ã: {feature_cols[:10]}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    output_dir = project_root / 'data' / 'processed'
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º train features –≤ CSV (—É–¥–æ–±–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π)
    output_file = output_dir / 'train_features.csv'
    save_dataframe(train_features, output_file)
    
    # –î–ª—è test –Ω—É–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å —Ñ–∏—á–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º train –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ª–∞–≥–æ–≤
    print("\nüîß –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏—á–µ–π –¥–ª—è test...")
    print("   ‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º train –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ª–∞–≥–æ–≤ –≤ test...")
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è test
    test_features = build_features_for_test(
        train,
        test,
        feature_groups=None,
        lag_periods=[1, 7, 14, 30, 90, 365],
        rolling_windows=[7, 30],
        verbose=True
    )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º test features –≤ CSV
    output_file = output_dir / 'test_features.csv'
    save_dataframe(test_features, output_file)
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è: –∞–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π —Å –ø–æ–º–æ—â—å—é –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö —É—Ç–∏–ª–∏—Ç
    print("\nüìä –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö —É—Ç–∏–ª–∏—Ç:")
    from src.features.validation import (
        get_feature_correlations_with_target,
        analyze_correlations,
        find_redundant_features
    )
    
    loaded_train = load_dataframe(output_file.parent / 'train_features.csv', verbose=False)
    
    # –¢–æ–ø-10 —Ñ–∏—á–µ–π –ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Å sales
    top_features = get_feature_correlations_with_target(
        loaded_train, target='sales', top_n=10
    )
    print(f"\n   –¢–æ–ø-10 —Ñ–∏—á–µ–π –ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Å sales:")
    print(f"   {top_features.to_string(index=False)}")
    
    # –ê–Ω–∞–ª–∏–∑ –≤—ã—Å–æ–∫–∏—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –º–µ–∂–¥—É —Ñ–∏—á–∞–º–∏
    high_corr = analyze_correlations(loaded_train, target='sales', threshold=0.95)
    if not high_corr.empty:
        print(f"\n   –ù–∞–π–¥–µ–Ω–æ {len(high_corr)} –ø–∞—Ä —Ñ–∏—á–µ–π —Å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π > 0.95:")
        print(f"   {high_corr.head(5).to_string(index=False)}")
    else:
        print("\n   ‚úÖ –ù–µ—Ç –ø–∞—Ä —Ñ–∏—á–µ–π —Å –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π (>0.95)")
    
    # –ü–æ–∏—Å–∫ –∏–∑–±—ã—Ç–æ—á–Ω—ã—Ö —Ñ–∏—á–µ–π
    redundant = find_redundant_features(loaded_train, target='sales', corr_threshold=0.98)
    if redundant:
        print(f"\n   –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–¥–∞–ª–∏—Ç—å {len(redundant)} –∏–∑–±—ã—Ç–æ—á–Ω—ã—Ö —Ñ–∏—á–µ–π:")
        print(f"   {redundant[:10]}")
    else:
        print("\n   ‚úÖ –ò–∑–±—ã—Ç–æ—á–Ω—ã—Ö —Ñ–∏—á–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    print("\n" + "=" * 80)
    print("‚úÖ –ì–û–¢–û–í–û!")
    print("=" * 80)
    print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   Train features: {train_features.shape}")
    print(f"   Test features: {test_features.shape}")
    print(f"   –í—Å–µ–≥–æ —Ñ–∏—á–µ–π: {len(feature_cols)}")


if __name__ == '__main__':
    import pandas as pd
    main()

